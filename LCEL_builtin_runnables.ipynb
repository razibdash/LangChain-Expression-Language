{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "70a1ce13",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv())\n",
    "GROQ_API_KEY = os.getenv(\"GROQ_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "56557e10",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\anaconda\\envs\\llmapp\\Lib\\site-packages\\langchain_groq\\chat_models.py:355: UserWarning: WARNING! max_completion_tokens is not default parameter.\n",
      "                    max_completion_tokens was transferred to model_kwargs.\n",
      "                    Please confirm that max_completion_tokens is what you intended.\n",
      "  warnings.warn(\n",
      "d:\\anaconda\\envs\\llmapp\\Lib\\site-packages\\langchain_groq\\chat_models.py:355: UserWarning: WARNING! top_p is not default parameter.\n",
      "                    top_p was transferred to model_kwargs.\n",
      "                    Please confirm that top_p is what you intended.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "model = ChatGroq(\n",
    "    api_key=GROQ_API_KEY,\n",
    "    model=\"llama3-70b-8192\",\n",
    "    temperature=1,\n",
    "    max_completion_tokens=1024,\n",
    "    top_p=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80c28b99",
   "metadata": {},
   "source": [
    "RunnablePassthrough\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "24d9d9c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "chain = RunnablePassthrough()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3f8638a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello, world!\n"
     ]
    }
   ],
   "source": [
    "result = chain.invoke(\"Hello, world!\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfcca2ff",
   "metadata": {},
   "source": [
    "RunnableLambda\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ecdb6ff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def russian_lastname(name: str) -> str:\n",
    "    return f\"{name}ovich\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b4f9156e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ivanovich\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.runnables import RunnableLambda\n",
    "\n",
    "chain = RunnablePassthrough() | RunnableLambda(russian_lastname)\n",
    "\n",
    "result = chain.invoke(\"Ivan\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "121027af",
   "metadata": {},
   "source": [
    "RunnableParallel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5bc397f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnableParallel\n",
    "\n",
    "chain = RunnableParallel(\n",
    "    {\n",
    "        \"operation_a\": RunnablePassthrough(),\n",
    "        \"operation_b\": RunnableLambda(russian_lastname)\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8a7e0004",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'operation_a': 'Barack Obama', 'operation_b': 'Barack Obamaovich'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke(\"Barack Obama\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f2673031",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "prompt = ChatPromptTemplate.from_template(\"tell me a curious fact about {soccer_player}\")\n",
    "\n",
    "output_parser = StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b376cdf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def russian_lastname_from_dictionary(person):\n",
    "    return person[\"name\"] + \"ovich\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3f50178f",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = RunnableParallel(\n",
    "    {\n",
    "        \"operation_a\": RunnablePassthrough(),\n",
    "        \"soccer_player\": RunnableLambda(russian_lastname_from_dictionary),\n",
    "        \"operation_c\": RunnablePassthrough(),\n",
    "    }\n",
    ") | prompt | model | output_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d4defb31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Here's one:\\n\\nAbramovich, the Russian billionaire and former owner of Chelsea FC, has a rather unusual hobby - he's a passionate collector of airships! Yes, you read that right. Abramovich has a fascination with dirigibles, those large, lighter-than-air aircraft that were popular in the early 20th century.\\n\\nIn fact, he reportedly owns several vintage airships, including a 1920s-era Zeppelin and a 1930s-era hydrogen-filled LZ-129 Hindenburg (yes, that Hindenburg, the one that famously caught fire in 1937).\\n\\nAbramovich has even been known to host lavish parties on his airships, complete with champagne and caviar. Who knew that beneath the tough, business-like exterior of a billionaire oligarch lay a romantic nostalgia for airships?\\n\\nI hope you found that curious fact about Abramovich interesting!\""
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\n",
    "    \"name1\": \"Jordam\",\n",
    "    \"name\": \"Abram\"\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06083f48",
   "metadata": {},
   "source": [
    "Let's see a more advanced use of RunnableParallel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3ee0762e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_10292\\1849545125.py:7: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 0.3.0. An updated version of the class exists in the langchain-huggingface package and should be used instead. To use it run `pip install -U langchain-huggingface` and import as `from langchain_huggingface import HuggingFaceEmbeddings`.\n",
      "  embeddings = HuggingFaceEmbeddings(\n",
      "d:\\anaconda\\envs\\llmapp\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough, RunnableParallel\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "embeddings = HuggingFaceEmbeddings(\n",
    "    model_name=\"sentence-transformers/all-MiniLM-L6-v2\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dc46ea28",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import TextLoader\n",
    "loader = TextLoader(\"data/Razib.txt\")\n",
    "documents = loader.load()\n",
    "load_data=documents[0].page_content\n",
    "vectorstore = FAISS.from_texts(\n",
    "    [load_data], embeddings, metadatas=[{\"source\": \"Razib.txt\"}]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "99761743",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The name of the author of the text is Razib Dash.\n"
     ]
    }
   ],
   "source": [
    "retriever = vectorstore.as_retriever()\n",
    "template = \"\"\"Answer the question based only on the following context:\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "chain = RunnableParallel(\n",
    "    {\n",
    "        \"context\": retriever,\n",
    "        \"question\": RunnablePassthrough(),\n",
    "    }\n",
    ") | prompt | model | StrOutputParser()\n",
    "result = chain.invoke(\"What is the name of the author of the text?\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4e02a51a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'लेखक का नाम रज़िब डैश (Razib Dash) है.'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from operator import itemgetter\n",
    "vectorstore = FAISS.from_texts(\n",
    "    [load_data], embeddings, metadatas=[{\"source\": \"Razib.txt\"}]\n",
    ")\n",
    "retriever = vectorstore.as_retriever()\n",
    "\n",
    "template = \"\"\"Answer the question based only on the following context:\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Answer in the following language: {language}\n",
    "\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "chain=(\n",
    "    {\n",
    "     \"context\": itemgetter(\"question\") | retriever,\n",
    "        \"question\": itemgetter(\"question\"),\n",
    "        \"language\": itemgetter(\"language\"),\n",
    "}| prompt | model | StrOutputParser()\n",
    ")\n",
    "\n",
    "chain.invoke({\n",
    "    \"question\": \"What is the name of the author of the text?\",\n",
    "    \"language\": \"hindi\"\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f96ace91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'রাজিব একজন শিক্ষাবিদ এবং প্রযুক্তিবিদ।'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\n",
    "    \"question\": \"What is Razib?\",\n",
    "    \"language\": \"bangla\"\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d772e61",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llmapp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
